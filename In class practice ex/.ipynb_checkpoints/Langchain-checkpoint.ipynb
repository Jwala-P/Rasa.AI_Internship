{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b91620-9f6f-412b-9a4b-2689fd066da3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.12\n",
      "  Using cached langchain-0.1.12-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (3.10.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.12)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.28 (from langchain==0.1.12)\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.31 (from langchain==0.1.12)\n",
      "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.12)\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.12)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain==0.1.12) (8.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.12) (2.1)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.31->langchain==0.1.12)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12)\n",
      "  Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.12) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.12) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.12) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.12) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.12) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.12) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.12) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.12) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.12) (1.0.0)\n",
      "Using cached langchain-0.1.12-py3-none-any.whl (809 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "Using cached langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Using cached langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, orjson, marshmallow, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-0.1.12 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147 marshmallow-3.26.1 orjson-3.10.18 packaging-23.2 typing-inspect-0.9.0\n",
      "Collecting langchain-openai==0.0.8\n",
      "  Using cached langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-openai==0.0.8) (0.1.53)\n",
      "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.0.8)\n",
      "  Using cached openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.0.8)\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (0.1.147)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.8.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-openai==0.0.8) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.0.8) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai==0.0.8) (0.4.6)\n",
      "Using cached langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
      "Using cached openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "Using cached tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "Using cached jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Installing collected packages: jiter, tiktoken, openai, langchain-openai\n",
      "Successfully installed jiter-0.10.0 langchain-openai-0.0.8 openai-1.82.0 tiktoken-0.9.0\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Collecting configparser\n",
      "  Using cached configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Using cached configparser-7.2.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: configparser\n",
      "Successfully installed configparser-7.2.0\n"
     ]
    }
   ],
   "source": [
    "# Install core LangChain package\n",
    "!pip install langchain==0.1.12\n",
    "\n",
    "# Install OpenAI integration for LangChain\n",
    "!pip install langchain-openai==0.0.8\n",
    "\n",
    "# Install other helpful packages\n",
    "!pip install python-dotenv configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36aa0843-cca1-4ea7-9a24-2805752940b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai==0.0.11\n",
      "  Using cached langchain_google_genai-0.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting google-generativeai<0.5.0,>=0.4.1 (from langchain-google-genai==0.0.11)\n",
      "  Using cached google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-google-genai==0.0.11) (0.1.53)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (4.25.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (4.11.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (0.1.147)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (8.2.3)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11)\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.11) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11) (2.2.3)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Using cached langchain_google_genai-0.0.11-py3-none-any.whl (28 kB)\n",
      "Using cached google_generativeai-0.4.1-py3-none-any.whl (137 kB)\n",
      "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: rsa, proto-plus, grpcio, googleapis-common-protos, grpcio-status, google-auth, google-api-core, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "Successfully installed google-ai-generativelanguage-0.4.0 google-api-core-2.24.2 google-auth-2.40.2 google-generativeai-0.4.1 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.62.3 langchain-google-genai-0.0.11 proto-plus-1.26.1 rsa-4.9.1\n"
     ]
    }
   ],
   "source": [
    "# Install Google Gemini integration for Langchain\n",
    "!pip install langchain-google-genai==0.0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f5843-843b-46c8-b284-438c9185076b",
   "metadata": {},
   "source": [
    "# Getting API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "676b64a4-9c01-44aa-b601-e202b2fa283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVailable API Credentials: openai, gemini\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Fix  encoding issues that might arise in different environments\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# Function to load API keys from config file\n",
    "def load_api_keys(config_file='config.ini'):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "\n",
    "    api_creds={}\n",
    "\n",
    "    # Extract OpenAI Key\n",
    "    if 'openai' in config and 'api_key' in config['openai']:\n",
    "        api_creds['openai_key']= config['openai']['api_key']\n",
    "\n",
    "    # If using Gemini, you can extract its key or set it manually\n",
    "    # Here, for example we'll create a placeholder\n",
    "\n",
    "    api_creds['gemini_key']=config['gemini']['api_key']\n",
    "\n",
    "    return api_creds\n",
    "\n",
    "# Try to load from config.ini, fall back to creating a dict for manual entry\n",
    "\n",
    "try:\n",
    "    api_creds = load_api_keys()\n",
    "    print(f\"AVailable API Credentials: {', '.join([k.replace('_key','') for k in api_creds if api_creds[k]])}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading config: {e}\")\n",
    "    print(\"Please add your API keys manually in the next cell.\")\n",
    "    api_creds = {'openai_key': '', 'gemini_key': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf92dc4d-03b9-438a-95d7-f2002b49c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for the APIs\n",
    "os.environ['OPENAI_API_KEY'] = api_creds.get('openai_key', '')\n",
    "os.environ['GOOGLE_API_KEY'] = api_creds.get('gemini_key', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddbf6b9-f86a-4ace-80f3-70c91a648ca0",
   "metadata": {},
   "source": [
    "# Intializing OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ef6d1b-7a45-4209-a081-cd2587a1a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Intialize OpenAI model\n",
    "# - model_name: Specifies which OpenAi model to use (gpt-3.5-turbo is a good default)\n",
    "# - temperature: Controls randomness (0.0 = deterministic)\n",
    "model = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189b5c2-ea75-4bba-ba8c-794b4f410d94",
   "metadata": {},
   "source": [
    "# A prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910f9af7-e534-41c4-a8dd-805aadcb504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the gun break up with the bullet? \n",
      "\n",
      "Because it just couldn't handle the recoil-tionship!\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template with a variable {topic}\n",
    "\n",
    "PROMPT = \"Tell me a joke about {topic}\"\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "\n",
    "# Create a chain by connecting the prompt template to the language model\n",
    "# The | operator in Langchain is used to connect components\n",
    "chain = prompt | model\n",
    "\n",
    "# Use the chain with a specific topic\n",
    "response = chain.invoke({\"topic\": \"guns\"})\n",
    "\n",
    "# Display the response\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7c508-52ca-4747-9752-58fb78f08ba4",
   "metadata": {},
   "source": [
    "# Gemini Model Intializtaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47355af-1058-4103-bfb3-9f83a4e133a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Gemini Model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "    # Intialize Gemini model\n",
    "    # convert_system_message_to_human = True helps Gemini understand system prompts\n",
    "    gemini_model = ChatGoogleGenerativeAI(\n",
    "        model = \"gemini-1.5-flash\", # Updated to the current model name\n",
    "        convert_system_message_to_human = True\n",
    "    )\n",
    "    print(\"Google Gemini Model initialized successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not initialize Gemini model: {e}\")\n",
    "    print(\"Continuing with OpenAI only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539a9d5-439e-4f28-b58b-eef472fa125a",
   "metadata": {},
   "source": [
    "# Prompt Template for Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2986ef18-0eb9-4d3e-9482-e27f2e87d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the statistician go to the beach?\n",
      "\n",
      "To test the waters!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "try: \n",
    "    # Define the prompt template\n",
    "    PROMPT = \"Tell me a joke about {topic}\"\n",
    "    prompt = ChatPromptTemplate.from_template(PROMPT)\n",
    "\n",
    "    # Chain the prompt with Gemini model\n",
    "    gemini_chain = prompt | model\n",
    "\n",
    "    # Generate a joke using Gemini\n",
    "    gemini_response = gemini_chain.invoke({\"topic\":\"statistics\"})\n",
    "    print(gemini_response.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Gemini model not available or failed to respond. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755bfab5-5b32-4487-8a45-5c6706516016",
   "metadata": {},
   "source": [
    "# Multiple topics through Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4157fc-67a5-4f00-a53e-167bdb5b7f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke about Anime:\n",
      "Why did the anime character go to therapy? \n",
      "\n",
      "Because he had too many issues to \"resolve\"!\n",
      "-----\n",
      "\n",
      "Joke about Statistics:\n",
      "Why did the statistician go to the beach?\n",
      "\n",
      "To test the waters!\n",
      "-----\n",
      "\n",
      "Joke about Python:\n",
      "Why did the Python programmer get lost in the jungle?\n",
      "\n",
      "Because he couldn't find his way out of the loop!\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define multiple topics for jokes\n",
    "\n",
    "topics = [\n",
    "    {\"topic\" : \"Anime\"},\n",
    "    {\"topic\" : \"Statistics\"},\n",
    "    {\"topic\" : \"Python\"}\n",
    "]\n",
    "# Process all topics in parallel using map\n",
    "# This is much more efficient than running them one by one in a lopp\n",
    "responses = chain.batch(topics)\n",
    "\n",
    "# Display all jokes\n",
    "for i, response in enumerate(responses):\n",
    "    print(f\"Joke about {topics[i]['topic']}:\")\n",
    "    print(response.content)\n",
    "    print(\"-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddd8e2-0359-430f-a9d2-4a9b0fc0154a",
   "metadata": {},
   "source": [
    "# Amnesia of langchain without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9908d630-1d16-4cb8-99fc-6f418fd42d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the first four colors of the rainbow ?\n",
      "Response: The first four colors of the rainbow are red, orange, yellow, and green.\n",
      "\n",
      "Query: And the other three ?\n",
      "Response: Apologies for the oversight. The other three major crime categories are property crime, violent crime, and drug-related crime. These categories cover a wide range of offenses including theft, assault, robbery, and drug trafficking. Each of these categories is further broken down into specific offenses and committed acts.\n",
      "\n",
      "Note: The model doesn't remember our previous question about rainbow colors.\n"
     ]
    }
   ],
   "source": [
    "# Memory Issuse\n",
    "# Create a very simple prompt template that just passes through the query\n",
    "prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "basic_chain = prompt | model\n",
    "\n",
    "# First question about rainbow colors\n",
    "response = basic_chain.invoke({\"query\": \"What are the first four colors of the rainbow ?\"})\n",
    "print(\"Query: What are the first four colors of the rainbow ?\")\n",
    "print(f\"Response: {response.content}\\n\")\n",
    "\n",
    "# Follow up question about the remaining colors\n",
    "response = basic_chain.invoke({\"query\": \"And the other three ?\"})\n",
    "print(\"Query: And the other three ?\")\n",
    "print(f\"Response: {response.content}\\n\")\n",
    "print(\"Note: The model doesn't remember our previous question about rainbow colors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335991f0-e247-4e2d-a440-2c29f8ed321a",
   "metadata": {},
   "source": [
    "# Giving memory to Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84ca13d1-cce8-4a4b-9472-f8324a60d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving memory to langchain\n",
    "\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "# Create a prompt template that includes conversation history\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # System message tells the model how to behave\n",
    "    (\"system\",\"Act as a helpful AI Assistant\"),\n",
    "    # This placeholder will be filled with conversatiin history\n",
    "    MessagesPlaceholder(variable_name = \"history\"),\n",
    "    # This is the user's current input\n",
    "    (\"human\",\"{input}\"),\n",
    "])\n",
    "\n",
    "# Initialize memory to store conversation history\n",
    "# k=3 means it will remember the last 3 exchanges () 3 user messages and 3 AI responses)\n",
    "memory = ConversationBufferWindowMemory(k=3, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f168e8a-631c-404d-9b04-a9be8c72006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what's in memory initially (should be empty)\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fab704f5-10c9-4333-a9e4-49ada09dc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the conversation chain with memory\n",
    "chain=(\n",
    "    # Step1 : Load the conversation history form memory\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    # Step2 : Format the prompt with history and current input\n",
    "    | prompt\n",
    "    # Step3 : Send to the language model\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9acd8bd-956f-45b0-bf18-ad4a29c49ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the first four colors of the rainbow ?\n",
      "AI: The first four colors of the rainbow are red, orange, yellow, and green.\n"
     ]
    }
   ],
   "source": [
    "# First question about rainbow colors\n",
    "user_input={\"input\" : \"What are the first four colors of the rainbow ?\"}\n",
    "response = chain.invoke(user_input)\n",
    "print(f\"User: {user_input['input']}\")\n",
    "print(f\"AI: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4363333-d3ba-429b-9a1c-f051b5b37f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check memory - still empty because we haven't saved the conversation yet\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e05808fc-7c9e-4348-9c9f-208040f6e080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='What are the first four colors of the rainbow ?'),\n",
       "  AIMessage(content='The first four colors of the rainbow are red, orange, yellow, and green.')]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important : Save the conversation to memory\n",
    "memory.save_context(user_input, {\"output\": response.content})\n",
    "\n",
    "# Now check what's in memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85935a50-0269-470c-bf50-17ef0a256511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: And the last 3 ?\n",
      "AI: The last three colors of the rainbow are blue, indigo, and violet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='What are the first four colors of the rainbow ?'),\n",
       "  AIMessage(content='The first four colors of the rainbow are red, orange, yellow, and green.'),\n",
       "  HumanMessage(content='And the last 3 ?'),\n",
       "  AIMessage(content='The last three colors of the rainbow are blue, indigo, and violet.')]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask a follow-up question\n",
    "user_input = {\"input\": \"And the last 3 ?\"}\n",
    "response = chain.invoke(user_input)\n",
    "print(f\"User: {user_input['input']}\")\n",
    "print(f\"AI: {response.content}\")\n",
    "\n",
    "# Save this turn to memory too\n",
    "memory.save_context(user_input, {\"output\": response.content})\n",
    "\n",
    "# Check updated memory\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53b7f0-2f0b-4f6b-a1a1-2dd5e31d3ec8",
   "metadata": {},
   "source": [
    "# Creating a ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c29d2d5-619a-4095-b143-ff99f48d1af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatbot(system_prompt='',history_window=3, temperature=1.0, llm=model):\n",
    "    # Use default system prompt if none provided\n",
    "    if not system_prompt:\n",
    "        system_prompt = \"Act as a helpful AI Assistant\"\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        # System message tells the model how to behave\n",
    "        (\"system\",system_prompt),\n",
    "        # This placeholder will be filled with conversatiin history\n",
    "        MessagesPlaceholder(variable_name = \"history\"),\n",
    "        # This is the user's current input\n",
    "        (\"human\",\"{input}\"),\n",
    "    ])\n",
    "\n",
    "    # Create memory\n",
    "    memory = ConversationBufferWindowMemory(k=history_window, return_messages=True)\n",
    "\n",
    "    # Create a conversation chaun\n",
    "    conversation_chain=(\n",
    "        # Step1 : Load the conversation history form memory\n",
    "        RunnablePassthrough.assign(\n",
    "            history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "        )\n",
    "        # Step2 : Format the prompt with history and current input\n",
    "        | prompt\n",
    "        # Step3 : Send to the language model\n",
    "        | llm\n",
    "    )\n",
    "\n",
    "    # Welcome message\n",
    "    print(\"Hello! I am your friendly chatbot. Let's Chat! (type 'STOP' to end)\")\n",
    "\n",
    "    # Chat loop\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_prompt = input('User: >>>')\n",
    "\n",
    "        # Check if user wants to exit\n",
    "        if user_prompt.strip().upper() == 'STOP':\n",
    "            print(\"Chatbot: >>> Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Generate and print the chatbot's reply\n",
    "        user_inp = {'input': user_prompt}\n",
    "        reply = conversation_chain.invoke(user_inp)\n",
    "        print(f\"Chatbot: >>>\\n{reply.content}\")\n",
    "\n",
    "        # Save to memory\n",
    "        memory.save_context(user_inp, {\"output\": reply.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c37c7eb-f538-4a29-97a8-ae3db73171ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am your friendly chatbot. Let's Chat! (type 'STOP' to end)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: >>> books to read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: >>>\n",
      "Sure! Here are some popular books across genres that you may enjoy:\n",
      "\n",
      "1. Fiction:\n",
      "   - \"To Kill a Mockingbird\" by Harper Lee\n",
      "   - \"1984\" by George Orwell\n",
      "   - \"The Great Gatsby\" by F. Scott Fitzgerald\n",
      "   - \"Pride and Prejudice\" by Jane Austen\n",
      "   - \"The Kite Runner\" by Khaled Hosseini\n",
      "\n",
      "2. Mystery/Thriller:\n",
      "   - \"Gone Girl\" by Gillian Flynn\n",
      "   - \"The Girl with the Dragon Tattoo\" by Stieg Larsson\n",
      "   - \"The Da Vinci Code\" by Dan Brown\n",
      "   - \"The Silent Patient\" by Alex Michaelides\n",
      "   - \"The Woman in the Window\" by A.J. Finn\n",
      "\n",
      "3. Science Fiction/Fantasy:\n",
      "   - \"Dune\" by Frank Herbert\n",
      "   - \"Harry Potter and the Sorcerer's Stone\" by J.K. Rowling\n",
      "   - \"The Hobbit\" by J.R.R. Tolkien\n",
      "   - \"The Martian\" by Andy Weir\n",
      "   - \"Ender's Game\" by Orson Scott Card\n",
      "\n",
      "4. Non-Fiction:\n",
      "   - \"Becoming\" by Michelle Obama\n",
      "   - \"Sapiens: A Brief History of Humankind\" by Yuval Noah Harari\n",
      "   - \"Educated\" by Tara Westover\n",
      "   - \"The Power of Habit\" by Charles Duhigg\n",
      "   - \"The Immortal Life of Henrietta Lacks\" by Rebecca Skloot\n",
      "\n",
      "I hope you find something here that interests you! Let me know if you have any specific preferences or themes in mind.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: >>> Suggest books similar to 'The seven husbands of Evelyn Hugo'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: >>>\n",
      "If you enjoyed \"The Seven Husbands of Evelyn Hugo\" by Taylor Jenkins Reid, you might like these books that share similar themes of Hollywood glamour, complex characters, and emotional depth:\n",
      "\n",
      "1. \"Daisy Jones & The Six\" by Taylor Jenkins Reid - Another book by the same author that explores the music industry in the 1970s through the intertwined stories of a rock band and its enigmatic lead singer, Daisy Jones.\n",
      "\n",
      "2. \"The Seven or Eight Deaths of Stella Fortuna\" by Juliet Grames - This multigenerational family saga follows the life of Stella Fortuna, an Italian immigrant living in America, and the events that shape her extraordinary life.\n",
      "\n",
      "3. \"The Swans of Fifth Avenue\" by Melanie Benjamin - A novel inspired by the friendship between author Truman Capote and socialite Babe Paley, exploring the glamour and intrigue of New York's high society in the 1950s and 1960s.\n",
      "\n",
      "4. \"The Seven Husbands of Evelyn Hugo\" by Anthony Doerr - A story of love, sacrifice, and survival set against the backdrop of World War II, following the lives of a blind French girl and a young German soldier.\n",
      "\n",
      "5. \"The Nightingale\" by Kristin Hannah - A historical fiction novel that tells the story of two sisters in Nazi-occupied France and their roles in the resistance movement, highlighting themes of love, sacrifice, and resilience.\n",
      "\n",
      "These books share elements of compelling storytelling, complex relationships, and rich historical settings similar to \"The Seven Husbands of Evelyn Hugo.\" I hope you find these recommendations enjoyable!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: >>> tell me a quote from the book 'Kite Runner'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: >>>\n",
      "Here is a powerful quote from the book \"The Kite Runner\" by Khaled Hosseini:\n",
      "\n",
      "\"For you, a thousand times over.\" - This quote is a recurring phrase in the novel and symbolizes the deep bond of loyalty and friendship between the two main characters, Amir and Hassan. It reflects the themes of redemption, guilt, and the enduring nature of their relationship despite the challenges they face.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: >>> sing a Tamil song\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: >>>\n",
      "I'm sorry, I can't sing a Tamil song as I'm just a text-based AI assistant. However, I can provide you with the lyrics to a Tamil song if you'd like. Just let me know the name of the song or any specific song lyrics you're interested in. I'm here to help with that!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: >>> yes, give me lyrics of a tamil movie song\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: >>>\n",
      "Of course! Here are the lyrics to the famous Tamil movie song \"Aalaporan Tamizhan\" from the movie Mersal:\n",
      "\n",
      "Aalaporan Tamizhan\n",
      "Arasangal Veeshumpothu\n",
      "Ullaththai Vidaatha Ulakam\n",
      "Athanaal Solla\n",
      "\n",
      "Unthan Thamizh Thandhai Neeye\n",
      "Thandhaikku Nee Irukkum Anbe\n",
      "Naangal Ketta Oru Kural Thaane\n",
      "Oorukke Varum Anbe\n",
      "\n",
      "Thamizhan Endru Sollada\n",
      "Thalai Nimirndhu Nillada\n",
      "\n",
      "I hope you enjoy these lyrics from the song \"Aalaporan Tamizhan\"! If you need more lyrics or information, feel free to ask.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: >>> stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: >>> Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Run the chatbot with default settings\n",
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5c867-a5ff-4053-a6d9-6c40e25865ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
